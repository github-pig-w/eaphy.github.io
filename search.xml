<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hexo 博客迁移]]></title>
    <url>%2F2022%2F09%2F12%2FHexo-%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[最近新入手 Macbook Pro，使用了6年的 windows 电脑将逐渐被替换，因此需要将老电脑中的Hexo博客迁移至新电脑。由于习惯了目前的Next主题样式，不想更换到最新版，特需要将现在的所有环境版本同步到我的 Parallels Desktop 中的windows11中。 1、安装 node.js 12.0.0 版本 1https://nodejs.org/download/release/v12.0.0/ 2、安装 git，配置环境变量，设置邮箱用户名 123git config --global user.name "eaphy"git config --global user.email "up_eaphy@foxmail.com" 3、安装 hexo-cli 2.0.0 版本 1npm install hexo-cli@2.0.0 -g 4、初始化博客根目录文件夹 1hexo init MyBlog 5、将已打包好的老文件夹里面所有文件粘贴到新文件夹，除git相关的文件夹除外 6、逐一执行清理、打包运行、推送等脚本]]></content>
      <categories>
        <category>网站运维</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud 组件原理]]></title>
    <url>%2F2020%2F03%2F06%2FSpringCloud-%E7%BB%84%E4%BB%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Eureka设计原则Eureka 采用纯 java 实现，其设计原则是AP，即可用性和分区容错性。它保证了注册中心的可用性，但舍弃了数据一致性，各节点上的数据有可能是不一致的，但是会最终一致。 存储结构 eureka 数据存储结构有两层，第一层是数据存储区，第二层是缓存区。 数据存储区，其实内部是一个双层的ConcurrentHashMap，第一层的key是spring.application.name，value是第二层ConcurrentHashMap；第二层ConcurrentHashMap的key是服务的InstanceId，value是Lease对象；Lease对象包含了服务详情和服务治理相关的属性。 双级缓存区，两者都用于服务信息的对外输出。 运作机制服务提供者向eureka注册、更新、删除服务时，会写入、更新、删除注册表以及全部写入最近修改队列，如果二级缓存有数据，那么清空二级缓存。 服务提供者，默认每隔30s向eureka发送心跳，表明自己活着，并且更新 Lease对象的 lastUpdateTimestamp。 服务消费者从eureka获取注册信息时，首先从一级缓存获取，如果一级缓存没有数据，那么一级缓存去二级缓存拉取数据，二级缓存也没有数据的话，二级缓存去注册表拉取数据，然后二级缓存返回给一级缓存，一级缓存返回给消费者。 eureka 自身存在一个Evict Task，会定期清理无效的服务，然后清空二级缓存，二级缓存本身是一个guava缓存，有失效机制，隔一段时间二级缓存会自己失效。eureka 自身还存在一个TimerTask，定期将二级缓存数据同步到一级缓存。 服务消费者自身也有一个缓存，用来缓存拉取的注册信息，首次拉取时，是全量从eureka缓存拉取，之后靠其自身的定时任务从eureka最近修改队列增量拉取，如果增量拉取失败再全量拉取。 Hystrix基本原理1.可以通过线程池和信号量两种方式实现资源隔离2.command key 代表了一类 command，一般对应服务的一个接口，command group 代表了一个线程池，command group 一般就对应一个服务，一个command group 可以包含多个 command key，多个接口共享一个线程池，如果 command key 要用自己的线程池，可以定义自己的 threadpool key 。3.线程池的大小，默认为10。4.queueSizeRejectionThreshold 用来设置等待队列大小，默认为5，超过线程池大小之后，先进入该队列，队列满，执行拒绝策略。 执行流程 1.执行command的四种方式： HystrixCommand，仅仅返回一个结果 execute() ； 阻塞，同步调用 queue()； 直接返回一个future，异步调用 HystrixObservableCommand，可能返回多个结果 observer()； 立即执行它的construct方法，得到结果 toObervable() ；返回一个observable对象，不会立即执行它的construct方法，订阅这个对象才会执行，得到结果]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>eureka</tag>
        <tag>hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目踩坑]]></title>
    <url>%2F2020%2F03%2F04%2F%E9%A1%B9%E7%9B%AE%E8%B8%A9%E5%9D%91%2F</url>
    <content type="text"><![CDATA[MQ 踩坑坑一、消费者宕机，消息积压百万挖坑： 实际项目中有发生过消费者挂掉，导致mq积压了上百万的消息。 填坑： 首先向公司申请了一批机器，构建了一个多倍于原有队列的mq，并且为他们设定了各自的消费者，然后临时修改原有的宕机消费者代码，使其接收到消息后不再消费，而是直接发到新建的mq中，然后重启恢复挂掉的消费者，让新建的mq的消费者去快速消费。消费完毕后，撤掉新建的mq，恢复原有代码，填坑完毕。 坑二、未按照预期顺序消费挖坑： 实际项目中有两台消费者，它们消费同一个mq，但是mq中只有一个队列，发生过本来对同一个数据的两个操作消息a、消息b，分别被两台消费者各消费了一个，但是呢，恰好本来应在消息a之后的消息b却被先消费掉了，导致数据库中产生的数据与预期的不一致。 填坑： 首先在mq中多加了一个队列，使每个队列对应一个消费者，然后在代码中实现了将同类型的（如同一个 id ）业务数据hash到同一个队列中，这样保证了每个队列中的相同消息顺序被同一个消费者消费，填坑完毕。 坑三、消息重复消费挖坑： 实际项目中发生过消费者消费了消息，但是还没有给mq发送ack确认的时候，宕机了，导致mq以为该消息没有被消费，从而没有从mq中移除，消费者重启后，又一次消费了该消息。 填坑：1、乐观锁，表中添加版本字段，修改数据时，判断version值是否变化，变化的就直接丢弃消息。2、去重表，可以使用业务中有唯一属性的字段，也可以自己生成一个全局唯一id，每消费一个消息，将其唯一属性存入redis，下次消费消息时，先查redis里面是否有此数据，有的话就直接丢弃消息。 Redis 踩坑坑一、rdb 数据恢复，总是恢复失败挖坑： 实际项目中，redis 同时开启了aof 和 rdb 持久化。由于操作失误，导致aof文件丢失，利用rdb文件，做数据恢复时，rdb 有数据，恢复出来的结果却没有数据。上述情况，是由于redis在启动时，如果开启了aof，会优先使用aof去恢复数据，如果没有aof文件，会自动创建一个空的文件，redis 根据空的aof文件，恢复了数据，并且同步到了有数据的rdb，导致恢复数据总是是失败。 填坑： 当 aof 文件损坏或丢失时，应该先停止redis，关闭aof，拷贝rdb备份，重启redis，确认恢复了数据，直接通过命令行config set appendonly yes 热修改redis配置，临时打开 aof， 此时，就会将内存中的数据写入一个aof文件，再次停止redis，手动修改配置文件aof为打开，重启redis。 JVM 踩坑坑一、堆内存 OOM，java heap space挖坑： 在项目中，我们对于一些数据的查询必须是带过滤条件的，比如集团id和机构id，而这些属性通过拦截器都封装在线程变量里，当某位同学做业务查询时，开启了异步线程，导致了从线程变量里获取到的数据为空，过滤条件未生效，一次查询加载了差不多几十万的数据出来，直接导致 OOM 填坑： 通过MAT工具分析了dump文件，找到了占用内存最多的那个线程，发现该线程的一个方法创建了一万多的对象，通过本地实践验证，发现是过滤条件失效的问题引发，修改之后，恢复正常。 顺便说一下，栈内存溢出，一般是方法递归调用产生，metaspace 内存溢出，一般是无限制的动态生成类产生。 坑二、服务周期性卡顿实际项目运行高峰期出现过，每隔十几分钟出现服务卡顿几秒的现象。 线上jvm配置：4核8G, 分配给jvm 4g，新生代1.5G（1.2G:150m:150m），老年代1.5G，永久代500m,栈1m(一般几百个线程，也就是几百兆) 我们的医疗系统，目前是有几十家医院在使用，高峰期的qps在1000左右，目前是部署了两台机器在运行，基本上也就是每台机器高峰期qps也就500左右，我所在的供应链模块，基本上一个对象平均在500字节，按照一个请求平均创建20个对象，差不多每秒产生的对象占用的堆内存在500* 500* 20=10m, 一分钟 60*10=600m, 4 分钟 就会触发ygc，由于部分接口比较耗时，观察发现会有180兆的对象没有被回收，此时，servior区只有150兆，已经放不下这180m的对象了，就会直接进入老年代，这样的话，差不多16分钟就会发生fullgc，这样对性能是有很大影响的。 优化过程：如果直接增大新生代的大小为2G（1.6G:200m:200m），老年代减为1G，这样的确可以保证servior能够放下每次ygc没回收的180m对象，但是，由于jvm垃圾回收的动态年龄规划，只要超过servior的一半内存，还是会把部分对象直接移入老年代，在某个时刻还是会触发fullgc，最终我们决定把新生代的比例改为6，即（1.2G:400m:400m）,这样每次ygc剩下的180m对象刚好不够400m的一半，不足于触发动态年龄规划，也就不会有对象进入老年代。我们调优的原则就是把gc都发生在年轻代，尽量不发生或少发生fullgc。]]></content>
      <categories>
        <category>面试相关</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring 多线程保证事务特性]]></title>
    <url>%2F2019%2F12%2F22%2Fspring-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%BF%9D%E8%AF%81%E4%BA%8B%E5%8A%A1%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[在业务逻辑中，开启多线程，可以提高性能，但是子线程报错，主线程难以捕获，导致事务特性难以保证。即主线程异常，如何回滚所有子线程，一个子线程异常，如何回滚主线程和其它所有子线程。经过实践，封装了一个工具类，用以保证多线程事务特性。思路：线程相互等待。主线程等子线程执行，如子线程有异常，主线程手动抛出，如无异常，子线程等主线程执行，如主线程有异常，回滚事务，如无，提交事务，等所有子线程执行完事务，主线程返回结果。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@Slf4jpublic class X &#123; public static Map&lt;Object,Throwable&gt; exceptionWeakMap = Collections.synchronizedMap(new WeakHashMap&lt;&gt;()); /** * 1.用于大量任务 for 循环开启线程 * 2.自动阻塞，for 循环所有线程任务结束，才会继续向下执行 * 3.支持线程报错的抛出，适用于查询报错，逻辑校验报错，不适用于增删改事务 * * @param list 需要操作的集合 * @param semapAmount 信号量（最多并发多少线程） * @param action 循环里执行的动作 */ public static &lt;T&gt; void asyncList(List&lt;T&gt; list,int semapAmount, Consumer&lt;? super T&gt; action)&#123; list = list == null ? new ArrayList&lt;&gt;() : list; CountDownLatch latch = new CountDownLatch(list.size()); Semaphore semaphore = new Semaphore(semapAmount); list.forEach(t -&gt; DoHelper.asyncCouSemProxy(semaphore, latch, () -&gt; action.accept(t))); try &#123; latch.await(30, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; throw new ServiceException(e); &#125; if (exceptionWeakMap.containsKey(latch)) &#123; log.error(exceptionWeakMap.get(latch).getMessage(), exceptionWeakMap.get(latch)); throw new RuntimeException(exceptionWeakMap.get(latch).getMessage()); &#125; &#125; /** * public int test()&#123; * Map&lt;String, CountDownLatch&gt; map = new HashMap&lt;&gt;(); * try &#123; * // 业务代码…… * X.asyncTransacTion(map,()-&gt;&#123;&#125;,()-&gt;&#123;&#125;……); * // 业务代码…… * &#125; catch (Exception e) &#123; * X.doCatch(e,map); * &#125; finally &#123; * X.doFinally(map); * &#125; * return 0; * &#125; * 1.只能在 try 里面写所有业务代码，catch 、finally 必须如上 * 2.不可用于for循环内，仅用于单次传多个线程 * 3.支持多线程事务，主线程报错，所有子线程事务回滚，一个子线程报错，其它子线程和主线程也回滚 * @param map 一个空map * @param runnables 多个线程 */ public static void asyncTransacTion(Map&lt;String,CountDownLatch&gt; map,Runnable...runnables)&#123; CountDownLatch threadLatch = new CountDownLatch(runnables.length); CountDownLatch transLatch = new CountDownLatch(runnables.length); CountDownLatch mainLatch = new CountDownLatch(1); map.put("threadLatch",threadLatch); map.put("transLatch",transLatch); map.put("mainLatch",mainLatch); Arrays.stream(runnables).forEach(runnable -&gt; DoHelper.asyncCoutProxy(mainLatch, threadLatch, transLatch, runnable)); try &#123; threadLatch.await(30, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; throw new ServiceException(e); &#125; if (exceptionWeakMap.containsKey(threadLatch)) &#123; throw new RuntimeException(exceptionWeakMap.get(threadLatch).getMessage()); &#125; &#125; public static void doCatch(Exception e,Map&lt;String,CountDownLatch&gt; map)&#123; X.exceptionWeakMap.put(map.get("threadLatch"), e); throw new ServiceException(e.getMessage()); &#125; public static void doFinally(Map&lt;String,CountDownLatch&gt; map)&#123; if (map.size()&gt;0) &#123; map.get("mainLatch").countDown(); try &#123; map.get("transLatch").await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 1234567891011121314151617@Slf4jpublic class DoHelper &#123; private static AsyncTaskExecutor asyncExecutor = (new AnnotationConfigApplicationContext(ThreadPoolConfig.class)).getBean(AsyncTaskExecutor.class); public static void asyncDo(Runnable...runnables)&#123; IntStream.range(0,runnables.length).forEach(i-&gt;asyncExecutor.execute(runnables[i])); &#125; public static void asyncCouSemProxy(Semaphore semaphore,CountDownLatch latch, Runnable...runnables)&#123; IntStream.range(0,runnables.length).forEach(i-&gt;asyncDo(ThreadProxy.getInstance(semaphore,latch,runnables[i]))); &#125; public static void asyncCoutProxy(CountDownLatch mainLatch,CountDownLatch threadLatch,CountDownLatch transLatch,Runnable runnable)&#123; asyncDo(ThreadProxy.getTransacTionInstance(mainLatch,threadLatch,transLatch,runnable)); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Componentpublic class ThreadProxy &#123; private static PlatformTransactionManager transactionManager; @Autowired public void setTransactionManager(PlatformTransactionManager transactionManager)&#123; ThreadProxy.transactionManager = transactionManager; &#125; public static Runnable getTransacTionInstance(CountDownLatch mainLatch,CountDownLatch threadLatch,CountDownLatch transLatch,Runnable runnable) &#123; return (Runnable) Proxy.newProxyInstance( ThreadProxy.class.getClassLoader(), runnable.getClass().getInterfaces(), (proxy, method, args) -&gt; &#123; DefaultTransactionDefinition def = new DefaultTransactionDefinition(); def.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW); TransactionStatus status = transactionManager.getTransaction(def); Object invoke = null; try &#123; invoke = method.invoke(runnable, args); &#125;catch (InvocationTargetException e)&#123; X.exceptionWeakMap.put(threadLatch,e.getTargetException()); &#125;finally &#123; threadLatch.countDown(); &#125; mainLatch.await(10, TimeUnit.MINUTES); try &#123; if (X.exceptionWeakMap.containsKey(threadLatch)) &#123; transactionManager.rollback(status); &#125; else &#123; transactionManager.commit(status); &#125; &#125;finally &#123; transLatch.countDown(); &#125; return invoke; &#125;); &#125; public static Runnable getInstance(Semaphore semaphore,CountDownLatch latch,Runnable runnable) &#123; return (Runnable) Proxy.newProxyInstance( ThreadProxy.class.getClassLoader(), runnable.getClass().getInterfaces(), (proxy, method, args) -&gt; &#123; try &#123; semaphore.acquire(); return method.invoke(runnable, args); &#125; catch (InvocationTargetException e) &#123; X.exceptionWeakMap.put(latch,e.getTargetException()); &#125; finally &#123; semaphore.release(); latch.countDown(); &#125; return null; &#125;); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839@Configuration@EnableAsyncpublic class ThreadPoolConfig implements AsyncConfigurer &#123; private AsyncTaskExecutor getExecutor()&#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(100); executor.setQueueCapacity(1000); executor.setKeepAliveSeconds(1); return executor; &#125; @Primary @Bean("taskExecutor") public AsyncTaskExecutor taskExecutor()&#123; return getExecutor(); &#125; @Bean("asyncExecutor") public AsyncTaskExecutor asyncExecutor()&#123; return getExecutor(); &#125; @Bean("otherExecutor") public AsyncTaskExecutor otherExecutor()&#123; return getExecutor(); &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return (throwable, method,obj)-&gt;&#123; throwable.printStackTrace(); System.out.println("Method name - " + method.getName()); for (Object param : obj) &#123; System.out.println("Parameter value - " + param); &#125; &#125;; &#125;&#125; 使用方法：直接调用 X.asyncList()、X.asyncTransacTion()，前者支持子线程报错抛到主线程，后者支持事务 12345678910111213141516171819202122@Transactionalpublic Object add() throws InterruptedException &#123; Map&lt;String, CountDownLatch&gt; map = new HashMap&lt;&gt;(); try &#123; ArrayList&lt;User&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt;19; i++) &#123; User u = new User(); u.setId(i); list.add(u); &#125; X.asyncList(list,2,user -&gt; System.out.println(user.getName())); X.asyncTransacTion(map, ()-&gt;&#123;userManager.save(list.get(0));&#125;, ()-&gt;&#123;userManager.save(list.get(1));&#125;); userManager.save(list.get(list.size()-1)); &#125;catch (Exception e)&#123; X.doCatch(e,map); &#125;finally &#123; X.doFinally(map); &#125; return ResponseModel.successful();&#125;]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stream 流用法]]></title>
    <url>%2F2019%2F10%2F27%2Fstream-%E6%B5%81%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[准备初始一个集合对象，以供测试： 12345List&lt;User&gt; list = new ArrayList&lt;&gt;();list.add(new User("张三", 12));list.add(new User("李四", 16));list.add(new User("王五", 18));list.add(new User("赵六", 20)); filter1list.stream().filter(u -&gt; u.getAge() &gt;= 18).collect(Collectors.toList()); 12User&#123;name='王五', age=18&#125;User&#123;name='赵六', age=20&#125; map1list.stream().map(User::getName).collect(Collectors.toList()); 1234张三李四王五赵六 sorted123list.stream().sorted(Comparator.comparing(User::getAge)).collect(Collectors.toList());list.stream().sorted(Comparator.comparing(User::getAge).reversed()).collect(Collectors.toList()); 12345678910User&#123;name='张三', age=12&#125;User&#123;name='李四', age=16&#125;User&#123;name='王五', age=18&#125;User&#123;name='赵六', age=20&#125;User&#123;name='赵六', age=20&#125;User&#123;name='王五', age=18&#125;User&#123;name='李四', age=16&#125;User&#123;name='张三', age=12&#125; list 转 map123list.stream().collect(Collectors.toMap(User::getAge, Function.identity()));list.stream().collect(Collectors.toMap(User::getAge,Function.identity(),(a,b)-&gt;b)); 123456789101112&#123;16=User&#123;name='李四', age=16&#125;, 18=User&#123;name='王五', age=18&#125;, 20=User&#123;name='赵六', age=20&#125;, 12=User&#123;name='张三', age=12&#125;&#125;&#123;16=User&#123;name='李四', age=16&#125;, 18=User&#123;name='王五', age=18&#125;, 20=User&#123;name='赵六', age=20&#125;, 12=User&#123;name='张三', age=12&#125;&#125; IntStream &gt; range(a,b), 包头不包尾，相当于 (int i = a;i&lt;b;i++);&lt; &gt;rangeClosed(a,b),包头包尾，相当于 (int i = a;i&lt;=b;i++)&lt; 123IntStream.range(0,list.size()).forEach(i-&gt;System.out.println(list.get(i).getName()));IntStream.rangeClosed(1,list.size()-1).forEach(i-&gt;System.out.println(list.get(i).getName())); 12345678张三李四王五赵六李四王五赵六]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es 常用查询语句]]></title>
    <url>%2F2019%2F09%2F12%2Fes-%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[1234567891011121314#添加数据PUT /eaphy/student/1&#123; "id":1, "age":11, "name":"小米", "city":"北京", "desc":"我是一个北京人"&#125;PUT /eaphy/student/2 &#123;"id":2,"age":12,"city":"南京","name":"小明","desc":"我是一个南京人"&#125;PUT /eaphy/student/3&#123;"id":3,"age":13,"city":"上海","name":"张三","desc":"我是一个上海人"&#125; 12345678910111213141516171819202122#修改数据POST /eaphy/student/1/_update&#123; "doc": &#123; "age":11 &#125;&#125;PUT /eaphy/student/1&#123; "id":1, "age":11, "name":"小花", "city":"北京", "desc":"我是一个北京人"&#125;# 删除一个type下所有数据POST /eaphy/student/_delete_by_query?conflicts=proceed&#123; "query":&#123; "match_all":&#123;&#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#查询数据 GET eaphy/student/1#条件查询，排序，分页GET eaphy/student/_search&#123; "query": &#123; "match": &#123; "desc": "是" &#125; &#125;, "sort": [ &#123; "age.keyword": &#123; "order": "desc" &#125; &#125; ], "from": 0, "size": 2&#125;# 条件查询，过滤查询GET eaphy/student/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123; "match": &#123; "name": "小" &#125; &#125;, &#123; "match": &#123; "city": "京" &#125; &#125; ], "filter": &#123; "range": &#123; "age": &#123; "gte": 12, "lte": 20 &#125; &#125; &#125; &#125; &#125;, "_source": ["name","age"]&#125;# 批量查询GET /eaphy/student/_mget&#123; "docs":[ &#123; "_id":1 &#125;, &#123; "_id":2 &#125; ]&#125;GET _mget&#123; "docs":[ &#123; "_index":"eaphy", "_type":"student", "_id":1 &#125;, &#123; "_index":"eaphy", "_type":"student", "_id":2 &#125; ]&#125;GET /eaphy/student/_mget&#123; "ids":[1,2]&#125;# 批量操作（一般是两行数据，一行定位，一行填充，delete 是一行）POST _bulk&#123;"delete":&#123;"_index":"eaphy","_type":"student","_id":1&#125;&#125;&#123;"create":&#123;"_index":"eaphy","_type":"student","_id":1&#125;&#125;&#123;"id":1,"age":11,"name":"小米","city":"北京","desc": "我是一个北京人"&#125;&#123;"update":&#123;"_index":"eaphy","_type":"student","_id":1&#125;&#125;&#123;"doc":&#123;"age":10&#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 解析]]></title>
    <url>%2F2019%2F09%2F01%2FElasticsearch-%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[一、shard es 中的 shard 分为 primary shard 和 replica shard，后者是前者的副本，负责容错，承担读请求 每个 shard 都可以独立完成创建索引，处理请求，是一个最小工作单元 每个 document 只会存在一个 primary shard 和 其对应的 replica shard 中 primary shard 在索引创建时固定，默认为 5，创建后不可修改， replica shard ，默认为1，可以修改 一个 index 包含多个 shard 二、扩容、容错 由于 primary shard 在索引创建后不可修改，所以 es 的扩容只能扩展 replica shard 的数量 一台mater node节点宕机后，其 primary shard 丢失，status 变红 集群进行master选举，自动选举一个新的node作为master 新的mater会将丢失的 primary shard 的某个 replica shard 提升为primary shard ，status 变黄，因为少一个 replica shard 重启宕机的 node ，新的master会将宕机后缺失的数据复制到该node上，原来的数据正常使用，status 变绿 三、全量替换、部分更新123456789101112131415PUT /eaphy/student/1&#123; "id":1, "age":11, "name":"小花", "city":"北京", "desc":"我是一个北京人"&#125;POST /eaphy/student/1/_update&#123; "doc": &#123; "age":11 &#125;&#125; 1.全量替换是先查询到document，修改信息，把信息全部发送到后台，后台发送put请求，进行全量替换，再把老的document标记为deleted，然后创建一个新的document2.部分更新是先查询到document，将更新的数据更新到document中，再把老的document标记为deleted，然后创建一个新的document，这个过程是在一个shard中完成的3.部分更新，减少了网络请求，减少了并发冲突。 四、document 路由一个index存在多个shard中，当一个document传进来时，其路由到某个具体shard的算法是： shard = hash(routing num) % number_of_primary_shards ps: 一个index有3个primary shard，每增删改查一个document时，会带过来一个routing num，默认是 document 的 id，然后求出hash值，与 3 求余，得到其应该定位到哪个shard中。 这就是 primary shard 数量不可修改的原因，会导致路由错误。 五、写一致性、quorum 机制我们在发送一个增删改操作时，可以带上一个consistency参数，指明我们想要的写一致性是什么。 123put index/type/id?consistency=oneput index/type/id?consistency=allput index/type/id?consistency=quorum one: 只要有一个primary shard 是活跃的就可以执行all： 必须所有 primary shard 和 replica shard是活跃的，才可执行quorum：必须大部分shard是活跃的，才能执行 quorum = int（（primary_num+replica_num）/ 2）+1，当replica_num&gt;1时生效ps: 3 个primary shard ，1个 replica shard ，共 3+3*1=6，那么 quorum = int((3+1)/2)+1 = 3 ,即要求6个shard中，至少3个shard活跃才能执行 quorum 不齐全时，默认会等待1分钟，也可以自己加参数 timeout 去设定]]></content>
      <categories>
        <category>开源框架</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试突击-中间件篇]]></title>
    <url>%2F2019%2F08%2F26%2F%E9%9D%A2%E8%AF%95%E7%AA%81%E5%87%BB-%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%AF%87%2F</url>
    <content type="text"><![CDATA[为什么使用MQ （优缺点）优点1.解耦一个系统可能有abcd四个模块，a 模块是核心模块，bcd 都需要从 a 获取数据，那么就需要在 a 模块写3个接口给bcd传输数据，这样的话，不管是模块增减，还是数据有变，都需要在a模块修改代码，强耦合。此时 ，mq 可以解耦，a 把数据发送到mq，bcd 自行订阅消费即可。 2.异步一个接口可能调用多个模块的接口，耗时较大。通过 mq ，可以让各个模块自行在后台消费，该接口只需要执行完自己的操作即可返回结果。 3.削峰系统可能在某个时间点，有大量请求过来，可能会导致系统直接崩掉，而其他时间请求很少，此时就可以通过 mq 存储数据，在后台以每秒系统能够承受的压力去处理请求。 缺点1.可用性降低系统依赖mq之后，必须保证mq的高可用，因为mq如果挂了的话，系统可能就崩了。 2.复杂性提高系统依赖mq之后，需要考虑如何解决消息的重复消费、消息的丢失、保证顺序消费。 3.一致性系统依赖mq之后，如果 a 系统成功发送到mq消息，此时返回结果成功，但是bcd系统消费失败了，导致一致性没有保证。 MQ 如何保证高可用RabbitMq 高可用1.普通集群有 a、b、c 三个节点，但是只有 b 节点的queue有元数据和实际数据，而 ac 节点只有queue的元数据，用户请求到ac时，那么ac需要从b节点获取实际数据，再返回给用户。只是提高了吞吐量。 缺点：1、3个节点内部传输消耗可能会过大2、b 节点挂了，服务就不可用了 2.镜像集群有a、b、c 三个节点，它们都存有queue的元数据和实际数据。 缺点：不是分布式，如果数据过大，节点存不下的话，不好处理。 Kafka 高可用kafka 是分布式的，它的数据是分批存在多个节点的，每个节点存一部分数据，每个节点还可以有自己的副本节点，主节点用来写数据，同步到副本，当一个主节点挂了之后，kafka会把它相应的副本节点提升为主节点，继续工作。 MQ 如何保证消息幂等性避免生产者重发消息基于mq的本身特性，对每条消息，mq系统内部会生成一个inner-msg-id，全局唯一，与业务无关；当mq接收到消息时，会先根据该id判断消息是否重复发送，进而决定是否接收该消息。 避免消费者重复消费1、乐观锁，修改数据时，判断version值是否变化，变化的就直接丢弃消息。2、去重表，可以使用业务中有唯一属性的字段，也可以自己生成一个全局唯一id，每消费一个消息，将其唯一属性存入redis，下次消费消息时，先查redis里面是否有此数据，有的话就直接丢弃消息。 MQ 如何保证消息顺序消费RabbitMq当一个mq有多个消费者时，会产生消费者消费信息顺序错乱的情况。可以通过设置多个queue，每个queue只对应一个消费者，根据业务中的字段，将相同类型的数据hash到同一个queue里，这样就保证了每个消费者消费的消息是按照我们预期的顺序执行。 Kafkakafka 的消息写入一个partition是一定有序的，同时一个 partition 只能被一个消费者消费。但是一个消费者读取消息时，可能会开启多个线程消费，毕竟单线程消费的能力有限，这就可能导致信息消费的顺序错乱。可以通过为每个 partition 开启多个内存队列，将相同类型的数据hash到同一个内存队列里，每个线程消费其中的一个内存队列，这样就保证了每个消费者消费的消息是按照我们预期的顺序执行。 MQ 如何保证消息100%投递成功消息落库，对消息状态打标在发送消息前，先把消息存入数据库，状态为 0 ，表示已投递待确认，通过消息的监听，收到消息投递成功返回的确认时，更改数据库状态为1，表示投递成功。当然，这中间会有一个定时任务，定时查询库中超过一定时间的状态还不是1的消息，把它重新发送。 消息的延迟投递，做二次确认，回调检查发送消息时，先发送一次消息到mq，再发送同样的延时消息到mq，这两个消息发送的队列是不一样的， 第一个是真正的消费者接受消息的队列，第二个延迟消息发送给一个专用的消息补偿服务接受消息的队列。当真正的消费者消费了消息时，也会发送一个消息到专用的消息补偿服务接受消息的队列，表明自己已经成功接收处理了该消息。此时，专用的消息补偿服务就把该消息落库。当时间超过延迟消息的延迟时间时，这时专用的消息补偿服务会接收到那条延迟消息，然后查库，发现确实没有这条消息，那就说明消息没有成功被消费，这时专用的消息补偿服务会再次从头走一遍上述过程。 未完待续……]]></content>
      <categories>
        <category>面试相关</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试突击-数据库篇]]></title>
    <url>%2F2019%2F08%2F26%2F%E9%9D%A2%E8%AF%95%E7%AA%81%E5%87%BB-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AF%87%2F</url>
    <content type="text"><![CDATA[缓存更新策略先更新数据库，再更新缓存缺点：1）、线程安全角度，同时有请求A和请求B进行更新操作，那么会出现a.线程A更新了数据库b.线程B更新了数据库c.线程B更新了缓存d.线程A更新了缓存 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。 2）、业务场景角度，如果写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。 先删除缓存，再更新数据库缺点：（1）请求A进行写操作，删除缓存（2）请求B查询发现缓存不存在（3）请求B去数据库查询得到旧值（4）请求B将旧值写入缓存（5）请求A将新值写入数据库 以上情况，可能会出现脏数据。 解决方案：延时删除策略：（1）先淘汰缓存（2）再写数据库（这两步和原来一样）（3）休眠1秒或其他时间，再次淘汰缓存 先更新数据库，再删除缓存缺点：a.缓存刚好失效b.请求A查询数据库，得一个旧值c.请求B将新值写入数据库d.请求B删除缓存e.请求A将查到的旧值写入缓存 以上情况，可能会出现脏数据。但是概率极低，因为一般 c 的写耗时高于 b 的读耗时，就很难出现 d 在 e 前面。 解决方案：1.延时删除策略：（1）先淘汰缓存（2）再写数据库（这两步和原来一样）（3）休眠1秒或其他时间，再次淘汰缓存2.重试机制：将删除失败的key发送至消息队列，自己消费消息，重试删除，直到成功。对业务代码有入侵。 热点key的重建优化互斥锁当发现key过期需要重建时，加锁执行重建逻辑，避免高并发导致的过多重建次数。 永不过期热点key，设置为没有过期时间，但是在逻辑上设置过期时间，即在value上加个过期时间的字段，每次查询时，发现逻辑时间过期的话，就使用异步线程去重建缓存。可能会存在短暂时间内的数据不一致。 未完待续……]]></content>
      <categories>
        <category>面试相关</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试突击-基础篇]]></title>
    <url>%2F2019%2F08%2F26%2F%E9%9D%A2%E8%AF%95%E7%AA%81%E5%87%BB-%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[HashMap存储结构数组+链表+红黑树，链表的存在是为了解决hash冲突，当链表长度大于8的时候，后面的数据存放在红黑树中。 特点 快速存储 快速查找（时间复杂度为o(1)） 可伸缩 线程不安全 数组下标计算数组默认大小为：16数组下标： hash &amp; （16-1） = hash % 16 扩容初始容量16，最大容量2的30次方，加载因子系数为 0.75，即容量达到四分之三时，开始扩容，扩容增量为原容量的一倍，即一次扩容后容量为32 操作流程put 操作： 首先判断key是否为null，若为null，直接插入数组第一个位置，数组原来有的数据，下标依次后移加一 若key不为null，计算key的hash值，取数组长度的模，得到其应该存储的数组位置 若该位置无值，直接插入 若该位置有值，判断链表中是否有key一样，有一样的话，覆盖原值，无一样的话，保存在链头 get 操作： 判断key是否为null，若为null，直接返回null的值 若key不为null，根据key的hash值，确定数组位置 遍历链表，返回key的hash值相同，且key一样的value JDK1.8 对 HashMap 的优化 由 数组+链表 的结构改为 数组+链表+红黑树 。拉链过长会严重影响hashmap的性能，所以1.8的hashmap引入了红黑树。在链表元素数量超过8时改为红黑树，少于6时改为链表，中间7不改是避免频繁转换降低性能。相对于链表，改为红黑树后碰撞元素越多查询效率越高。链表O(n)，红黑树O(logn)。 优化了高位运算的hash算法：h^(h&gt;&gt;&gt;16)，将hashcode无符号右移16位，让高16位和低16位进行异或。 扩容后，元素要么是在原位置，要么是在原位置再移动2次幂的位置，且链表顺序不变。不需要重新计算hash，只需要根据原来hash值新增的bit是1还是0分别放进两个链表lo和hi（非红黑树的情况）里，0的话索引没变，1的话索引变为原索引加原来的数组长度。因为用的尾插法所以新数组链表不会倒置，多线程下不会出现死循环。 put 方法链表头插改为尾插 线程池四大组件1、线程池管理器（ThreadPoolManager）:用于创建并管理线程池2、工作线程（WorkThread）: 线程池中线程3、任务接口（Task）:每个任务必须实现的接口，以供工作线程调度任务的执行。4、任务队列:用于存放没有处理的任务。提供一种缓冲机制。 四大种类1.CachedThreadPool（可缓存的线程池，只有非核心线程）2.SecudleThreadPool（周期性执行任务的线程池）3.SingleThreadPool（单线程线程池，适用于有顺序的任务场景）4.FixedThreadPool（定长的线程池，只有核心线程） 12345678910public void threadpool()&#123; Executor executor1 = Executors.newSingleThreadExecutor(); Executor executor2 = Executors.newFixedThreadPool(5); Executor executor3 = Executors.newCachedThreadPool(); ScheduledExecutorService executor4 = Executors.newScheduledThreadPool(5); //ScheduleAtFixedRate 每次执行时间为上一次任务开始起向后推一个时间间隔,上个任务没结束，会等待其结束再执行下个任务 executor4.scheduleAtFixedRate(()-&gt;&#123;&#125;,1,1,TimeUnit.SECONDS); //ScheduleWithFixedDelay 每次执行时间为上一次任务结束起向后推一个时间间隔 executor4.scheduleWithFixedDelay(()-&gt;&#123;&#125;,1,1,TimeUnit.SECONDS); &#125; 拒绝策略1.AbortPolicy：不执行新任务，直接抛出异常2.DisCardPolicy：不执行新任务，也不抛异常3.DisCard OldSetPolicy，新任务替换任务队列的第一个任务4.CallerRunsPolicy：直接调用execute执行当前任务。 死锁必要条件互斥条件：一个资源每次只能被一个进程使用，即在一段时间内某 资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。 请求与保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 不可剥夺条件:进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。 循环等待条件: 若干进程间形成首尾相接循环等待资源的关系 避免死锁1、加锁顺序，即当需要获取a，b两个锁时，只能先获取到a锁，才能获取b锁。2、加锁时限，即在指定的时间内获取不到锁，就放弃等待锁，并释放自己现在所持有的锁。3、破坏必要条件 死锁实例12345678910111213141516171819202122232425262728293031class HoldLockThread implements Runnable&#123; private String locka; private String lockb; public HoldLockThread(String locka,String lockb)&#123; this.locka = locka; this.lockb = lockb; &#125; @Override public void run() &#123; synchronized (locka)&#123; System.out.println(Thread.currentThread().getName() + " 自己持有：" + locka + " 尝试获得: " + lockb); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (lockb)&#123; System.out.println(Thread.currentThread().getName() + " 自己持有：" + lockb + " 尝试获得: " + locka); &#125; &#125; &#125;&#125;public class DeadLockDemo &#123; public static void main(String[] args) throws InterruptedException &#123; String locka = "locka"; String lockb = "lockb"; new Thread(new HoldLockThread(locka,lockb),"AAA").start(); new Thread(new HoldLockThread(lockb,locka),"BBB").start(); &#125;&#125; volatilevolatile 保证了变量的可见性、有序性、不保证原子性（只保证极少数原子性操作）。 可见性volatile 变量的内存可见性是基于内存屏障（Memory Barrier）实现。内存屏障其实就是一个lock前缀的cpu指令，lock 前缀的指令在多核处理器下，会强制将当前行的数据写回到主内存，这会导致其他cpu缓存的该数据失效，进而需要重新读取。 有序性为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。volatile 写操作是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。 屏障 作用 StoreStore 禁止上面的普通写和下面的 volatile 写重排序。 StoreLoad 禁止上面的 volatile 写与下面可能有的 volatile 读/写重排序。 LoadLoad 禁止下面所有的普通读操作和上面的 volatile 读重排序。 LoadStore 禁止下面所有的普通写操作和上面的 volatile 读重排序。 原子性volatile 不能保证原子性，存在少数情况可以保障（可以保证32位虚拟机系统中 long、double类型单次赋值操作的原子性）。 在 java 中，基本数据类型是天然存在原子性的，如 int i =1；但是在32位虚拟机系统中 long、double的赋值操作，如 long i=3；是不具有原子性的，因为long、double是64位的，在32位虚拟机系统中，多线程并发执行 long i=3；可能会存在一个线程在修改低32位，另一个线程在修改高32位，导致最后赋值操作的结果不是预期的。但是通过 volatile 修饰可以保证其原子性。 synchronizedsynchronized 保证了变量的可见性、有序性、原子性 。 1234567891011synchronized(this)&#123; # monitorenter # load # acquire do something…… # release # monitorexit # store&#125; synchronized 也是通过内存屏障来实现3个特性。当代码运行到 synchronized 关键字时，1.会生成一个 monitorenter 指令，表示进入，2.然后通过 load 指令执行 refresh 操作，即把别的处理器修改过的最新值加载到自己工作内存；3.通过 acquire 指令禁止上文与屏障代码指令重排，4.通过 release 指令禁止下文与屏障代码指令重排； .// 有序性5.然后通过 monitorexit 指令退出屏障，6.紧接着通过 store 执行 flush 操作 ，即将修改的值刷回到主内存。 .// 可见性7.其原子性保障是通过 monitorObject 对象，运用 cas 加锁实现。 伪共享cpu 缓存行cpu 的处理速度与访问内存、磁盘相比，相差过大，所以有了 cpu 的三级缓存，L1到L3缓存容量依次增大，查找耗时依次增大，cpu 查找顺序依次是L1、L2、L3、主存。cpu 读取数据通常一次读取一个缓存行（Cache Line），缓存行的大小通常是64字节，这意味着即使只操作1字节的数据，cpu 最少也会读取这个数据所在的连续64字节数据。 缓存行状态，MESI 协议MESI协议描述了多核处理器中一个缓存行的状态。每个缓存行有4个状态，分别是：M（修改，Modified）： 本地处理器已经修改缓存行，它的内容与主内存中的内容不一样，并且此 cache 只有本地一拷贝(专有)；E（专有，Exclusive）： 缓存行内容和内存中的一样，而且其它处理器都没有这行数据；S（共享，Shared）： 缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝；I（无效，Invalid）： 缓存行失效, 不能使用。 Java中的伪共享一个缓存行的大小是64字节，如果存放8字节 long 类型，那么一个缓存行可以存储 8个 long类型的变量，如果我们有两个 long 类型变量A、B，它们在一个缓存行，那么当一个线程要修改A时，需要加载该缓存行，另一个线程要修改B时，也需要加载该缓存行，看似它们修改的不是一个变量，但是却是同一个缓存行，只要有一个线程修改，那么该缓存行在其他线程就会失效，需要重新读取。 避免伪共享 填充自己把变量填充到64字节 @Contended 注解（要设置 -XX:-RestrictContended=false，它默认为 true，意味仅限 JDK 内部的类使用）ConcurrentHashMap 源码里面的 size() 方法使用的是分段的思想来构造的，每个段使用的类是 CounterCell，它的类上就有 @sun.misc.Contended 注解。 未完待续……]]></content>
      <categories>
        <category>面试相关</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 原理解析]]></title>
    <url>%2F2019%2F07%2F29%2FRedis-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[数据类型Stringstring 类型通过int、sds作为数据结构，int用来存储整型数据，sds存放字节、字符串、浮点型数据。redis3.2分支引入了五种sdshdr类型，目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存，每次在创建一个sds时根据sds的实际长度判断应该选择什么类型的sdshdr。 Listlist 可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素。 redis3.2之前，List类型的value对象内部以linkedlist或者ziplist来实现, 当list的元素个数和单个元素的长度比较小 的时候，Redis会采用ziplist（压缩列表）来实现来减少内存占用。否则就会采用linkedlist（双向链表）结构。 redis3.2之后，采用的一种叫quicklist的数据结构来存储list，列表的底层都由quicklist实现。 这两种存储方式都有优缺点，双向链表在链表两端进行push和pop操作，在插入节点上复杂度比较低，但是内存开 销比较大； ziplist存储在一段连续的内存上，所以存储效率很高，但是插入和删除都需要频繁申请和释放内存； quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist，其实就是linkedlist和ziplist的结合，quicklist 中每个节点ziplist都能够存储多个数据元素 Hashmap提供两种结构来存储，一种是hashtable、另一种是前面讲的ziplist，数据量小的时候用ziplist. SetSet在的底层数据结构以intset或者hashtable来存储。当set中只包含整数型的元素时，采用intset来存储，否则， 采用hashtable存储，但是对于set来说，该hashtable的value值用于为NULL。通过key来存储元素 。 Sorted-Set在集合类型的基础上，有序集合类型为集合中的每个元素都关联了一个分数，这使得我们不仅可以完成插入、删除 和判断元素是否存在等集合类型支持的操作，还能获得分数最高(或最低)的前N个元素、获得指定分数范围内的元 素等与分数有关的操作。虽然集合中每个元素都是不同的，但是他们的分数却可以相同 zset类型的数据结构就比较复杂一点，内部是以ziplist或者skiplist+hashtable来实现，这里面最核心的一个结构就 是skiplist，也就是跳跃表 过期删除原理 周期性随机抽取20个设置了过期时间的key，判断是否过期，过期则删除。 get 时，判断key是否过期，过期则删除。 持久化RDB当符合条件时，fork子进程生成一个dump.rdb的快照文件。有可能丢失数据条件1：修改配置文件： 123save 900 1 //900s之内有一个key发生改变，触发快照save 300 10 //300s之内有10个key发生改变，触发快照save 60 10000 //60s之内有10000个key发生改变，触发快照 条件2：执行 save 命令 （阻塞所有请求），触发快照执行 bgsave 命令 （不会阻塞请求），触发快照 条件3：执行命令 flushall，触发快照 条件4:主从复制时，触发快照 AOF在aof文件中保存增删改的的操作指令。当aof文件过大时，可以进行压缩，把内存中的数据生成一个临时的aof文件，然后覆盖原文件。 内存回收策略no-enviction：内存不足时，报错 allkeys-lru：挑选最近最少使用的数据淘汰 allkeys-random：随机选择数据淘汰 volatile-lru：从已设置过期时间的数据中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据中随机选择数据淘汰 主从架构主从复制原理当启动一个 slave 节点的时候，它会发送一个 psync 命令给 master 节点，如果是第一次连接 master，那么会触发一次全量复制，mater 在后台启动一个线程，在内存中生成一个 RDB 快照文件，同时还会将所有收到的写命令缓存在内存中，然后将 RDB 发送给slave节点，slave节点会先将快照写入本地磁盘，然后再从本地磁盘加载到内存中，然后 master 节点将内存中缓存的写命令发送给 slave，slave 也会同步这些数据。如果不是第一次连接 master ，那么 master 仅仅复制 slave 部分缺少的数据。 主从复制的断点续传如果主从复制中，网络连接断掉了，可以接着上次复制的地方，继续复制下去。mater 节点会在内存中有一个backlog，mater 和 slave 都会保存一个 offset 和 mater run id，如果网络连接断开了，slave 会判断 mater run id 是否一样，一样的话让 mater 从上次的 offset 开始继续复制，如果没有找到 offset ，会进行一次全量复制。 mater run id 不一样就重新全量复制。 无磁盘化复制master 直接在内存中创建 rdb ，然后发送给 slave ，不会在自己本地落盘 repl-diskless-syncrepl-diskless-sync-delay 延迟复制，因为要等多 slave 节点的连接成功。 过期 key 处理slave 不会过期 key，只会等待 master 过期key，如果 master 过期了一个key，或者通过lru淘汰了一个key，那么会模拟一条del命令发送给 slave。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2F2019%2F07%2F22%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[介绍在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 用途主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 源码123public interface Gun &#123; public void openFire();&#125; 123456public class Awm implements Gun &#123; @Override public void openFire() &#123; System.out.println("Awm 火力覆盖中……"); &#125;&#125; 123456public class Akm implements Gun &#123; @Override public void openFire() &#123; System.out.println("Akm 火力覆盖中……"); &#125;&#125; 123456789101112131415161718192021public class choose &#123; Gun wuqi; public choose(Gun gun) &#123; super(); this.wuqi = gun; &#125; public void run() &#123; wuqi.openFire(); &#125; public wuqi getWuqi() &#123; return wuqi; &#125; public void setWuqi(Gun wuqi) &#123; this.wuqi = wuqi; &#125;&#125; 12345678public class celuetest &#123; public static void main(String[] args) &#123; choose choose = new choose(new Awm()); choose.run(); choose.setWuqi(new Akm()); choose.run(); &#125;&#125; 123//输出结果Awm 火力覆盖中……Akm 火力覆盖中…… 总结通过一个接口定义一套行为，各个不同的类实现该接口，运行时自由切换实现方式。如上述代码中，枪有很多种，但是其功能都是开火击杀，只不过不同的枪的射击细节不同，awm 是拉栓单发狙，akm 是连发步枪，当我们用枪时，自由选择，awm 就一枪一枪搞，akm 就一梭子拉到底。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis - 手写简易版1.0]]></title>
    <url>%2F2019%2F07%2F19%2Fmybatis-%E6%89%8B%E5%86%99%E7%AE%80%E6%98%93%E7%89%881-0%2F</url>
    <content type="text"><![CDATA[架构组成 sqlsessionsqlsession 是我们直接操作数据的入口，我们通过它来获取代理mapper，进而操作数据库，获取数据。其中包含了configuration、executor的引用，sqlsession 本身不做具体的事情，而是委托configuration、executor去做具体的操作。 configurationconfiguration 是一个配置类，用它来做一些框架的配置，包括初始化所有 mapper 、statement。用它来真正的获取mapper、statement。 executorexecutor 主要用来数据库的连接、执行 crud 等操作。 proxyproxy 主要用来生成代理mapper，我们不是通过真实的mapper接口去执行具体的业务，而主要是通过代理mapper去执行。 主要原理： sqlssion 持有 configuration、executor 的引用，以及获取 mapper 代理、执行 crud 的外露接口，当然，获取 mapper 代理由configuration 去具体执行，crud 操作由 executor 去具体执行，sqlsession 只是一个主管，分配任务即可。 configuration 在实例化时，会初始化且保存所有 mapper 代理，以及 statement（sql语句），并且外露一个获取 mapper 代理的接口、一个获取statement的接口给 sqlsession。（mapper代理的保存方式是一个map，key是真实的mapper接口，value是该接口的代理对象；statement 的保存方式是一个map，key是 mapper 接口的方法名，value是该方法的sql语句） executor 就是建立数据库连接，外露crud接口给 sqlsession，供其差遣。 proxy 通过 sqlsession 委托 configuration 获取 statment ， 委托 executor 去执行 sql 语句获取结果。（我们知道 proxy 生成的代理对象必会走invoke方法，在invoke方法中，我们可以得到mapper具体执行的哪个方法，根据该方法名获取到statment，委托给configuration、sqlsession）。 核心代码sqlsession12345678910111213141516171819202122public class SqlSession &#123; private ConfiguRation configuRation; private Executor executor; public SqlSession(ConfiguRation configuRation,Executor executor)&#123; this.configuRation = configuRation; this.executor = executor; &#125; public ConfiguRation getConfiguRation()&#123; return configuRation; &#125; public &lt;T&gt; T getMapper(Class&lt;T&gt; clazz)&#123; return configuRation.getMapper(clazz,this); &#125; public &lt;T&gt; T selectByPrimaryKey(String statement, String parameter)&#123; return executor.query(statement,parameter); &#125;&#125; configuration123456789101112131415161718192021222324252627public class ConfiguRation &#123; private Map&lt;Class&lt;?&gt; ,BatisProxyFactory&gt; mapperHouse = new HashMap&lt;&gt;(); public static final Map&lt;String, String&gt; mappedStatements = new HashMap&lt;&gt;(); public ConfiguRation() &#123; mapperHouse.put(UserMapper.class,new BatisProxyFactory(UserMapper.class)); mappedStatements.put("com.eaphy.handBatis.UserMapper.selectByPrimaryKey" , "select * from t_user where id = %d"); &#125; public boolean containStatement(String statementName) &#123; return mappedStatements.containsKey(statementName); &#125; public String getMappedStatement(String id) &#123; return mappedStatements.get(id); &#125; public &lt;T&gt; T getMapper(Class&lt;T&gt; clazz, SqlSession sqlSession) &#123; BatisProxyFactory proxyFactory = mapperHouse.get(clazz); if (proxyFactory == null) &#123; throw new RuntimeException("Type: " + clazz + " can not find"); &#125; return (T)proxyFactory.newInstance(sqlSession); &#125;&#125; executor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Executor &#123; public &lt;T&gt; T query(String statement, String parameter) &#123; Connection conn = null; PreparedStatement preparedStatement = null; User user = null; try &#123; conn = getConnection(); preparedStatement = conn.prepareStatement(String.format(statement, Integer.parseInt(parameter))); preparedStatement.execute(); ResultSet rs = preparedStatement.getResultSet(); user = new User(); while (rs.next()) &#123; user.setId(rs.getInt(1)); user.setName(rs.getString(2)); user.setPhone(rs.getString(3)); user.setEmail(rs.getString(4)); user.setQq(rs.getString(5)); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; return (T)user; &#125; public Connection getConnection() throws SQLException &#123; String driver = "com.mysql.cj.jdbc.Driver"; String url = "jdbc:mysql://127.0.0.1:3306/eaphy?serverTimezone=UTC"; String username = "root"; String password = "123456"; Connection conn = null; try &#123; Class.forName(driver); conn = DriverManager.getConnection(url, username, password); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn; &#125;&#125; proxy1234567891011121314151617public class BatisProxy implements InvocationHandler &#123; private SqlSession sqlSession; public BatisProxy(SqlSession sqlSession) &#123; this.sqlSession = sqlSession; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (sqlSession.getConfiguRation().containStatement(method.getDeclaringClass().getName()+"."+method.getName())) &#123; String sql = sqlSession.getConfiguRation().getMappedStatement(method.getDeclaringClass().getName()+"."+method.getName()); return sqlSession.selectByPrimaryKey(sql, args[0].toString()); &#125; return method.invoke(proxy, args); &#125;&#125; 12345678910111213public class BatisProxyFactory&lt;T&gt; &#123; private Class&lt;T&gt; mapperInterface; public BatisProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public T newInstance(SqlSession sqlSession) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, new BatisProxy(sqlSession)); &#125;&#125; mapper123public interface UserMapper &#123; User selectByPrimaryKey(int id);&#125; Test12345678@Datapublic class User &#123; private Integer id; private String name; private String phone; private String email; private String qq;&#125; 12345678910@Slf4jpublic class UserTest &#123; public static void main(String[] args) &#123; SqlSession sqlSession = new SqlSession(new ConfiguRation(), new Executor()); UserMapper userMapper = sqlSession.getMapper(UserMapper.class); User user = userMapper.selectByPrimaryKey(1); log.info("用户信息：&#123;&#125;",user); &#125;&#125; 12/* 执行结果 */用户信息：User(id=1, name=张三12233, phone=12345672233, email=1234567@qq2233.com, qq=12345672233)]]></content>
      <categories>
        <category>开源框架</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 存储引擎]]></title>
    <url>%2F2019%2F07%2F11%2Fmysql-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[介绍 可插拔的插件方式 存储引擎是指定在表之上的，每个表可以指定专用的存储引擎 不管采用什么存储引擎，都会在数据区产生对应的一个frm文件（表结构定义描述文件） CSV 存储引擎特点： 不能定义没有索引、列定义必须非空，不能设置自增列（不适用大表或数据的在线处理） csv数据的存储用 ， 隔开，可以直接编辑csv文件进行数据的编排（数据安全性低） 注：编辑之后，要生效使用 flush table xxx 命令 应用场景： 数据的快速导出导入 表格直接转换成csv Archive 存储引擎特点： 只支持insert和select操作 只允许自增ID建立索引 行级锁 不支持事务 数据占用磁盘少 应用场景： 日志系统 大量的设备数据采集 Memory 存储引擎数据都是存储在内存中，IO效率高，服务重启数据丢失，内存数据表默认只有16M。 特点： 支持hash索引，B tree 索引，默认hash（查找复杂度O(1)） 字段长度都是固定长度 varchar（32） = char （32） 不支持大数据存储类型，如blog、text 表级锁 应用场景： 等值查找热度较高的数据 查询结果内存中的计算，作为临时表存储需要计算的数据 Myisam 存储引擎mysql 5.5 之前默认的存储引擎，较多的系统表也还是用这个引擎，系统临时表也会用到该引擎。 特点： select count(*) from table 无需进行数据的扫描 数据（MYD）和索引（MYI）分开存储 表级锁 不支持事务 索引与数据分开存储，不管以什么字段建立索引，都会存储数据的一个地址的指针，根据该指针找到数据。 Innodb 存储引擎mysql 5.5 之后默认的存储引擎。 特点： 支持事务 行级锁 聚集索引（主键索引）的方式进行数据存储 支持外键 以主键为索引来组织数据的存储，在叶子节点存储了该条数据的所有数据，如果其他字段做索引，会在该字段索引的叶子节点存储主键索引的值，再根据该值在主键索引种找到数据。如果没有明确指定主键索引，会自动生成 6 byte的 int 主键索引。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>存储引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 解析]]></title>
    <url>%2F2019%2F07%2F10%2Fmysql-%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[索引是什么索引是为了加快对表中数据行的检索而创建的一种分散存储的数据结构。 为什么用索引 索引能极大的减少存储引擎需要扫面的数据量 索引可以把随机IO变成顺序IO 索引可以帮助我们在进行分组、排序等操作时，避免使用临时表 为什么是 B+Tree二叉查找树 二叉查找树的缺点就是容易发生极端化，导致某个节点太长。 平衡二叉查找树 平衡二叉查找树的缺点就是数据太多时，导致树的深度太高，IO操作次数增多，耗时大，其次，每个节点存储的数据太少。 多路平衡二叉查找树（B Tree） 加强版多路平衡二叉查找树（B+ Tree） 索引的重要知识列的离散性列的离散性 = count（distinct col）/ count(col) ,值越大，离散性越好，选择性越高。 最左匹配原则对索引中的关键字进行比对，一定是按照从左往右进行，且不可跳过。 联合索引联合索引列选择原则： 经常用的列优先（最左匹配） 离散性高的列优先（离散高原则） 宽度小的列优先（最少空间原则） 覆盖索引如果查询列可通过索引节点中的关键字直接返回，则该索引称之为覆盖索引。覆盖索引可以减少数据库的IO ，将随机IO变为顺序IO，可提高查询性能。 ps：索引列：（name+phone）查询语句：select name,phone from user where name = ? ;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot 异步任务(taskExecutor+FutureTask)]]></title>
    <url>%2F2019%2F07%2F08%2Fspringboot-%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1-taskExecutor-futureTask%2F</url>
    <content type="text"><![CDATA[不使用异步提交任务12345678910111213@Servicepublic class UserManager &#123; // 模拟耗时业务 public int sleep1() throws InterruptedException &#123; Thread.sleep(2000); return 2; &#125; // 模拟耗时业务 public int sleep2() throws InterruptedException &#123; Thread.sleep(3000); return 3; &#125;&#125; 12345678910111213141516171819@RestController@RequestMapping("/user")public class UserController &#123; @Resource private UserManager userManager; @GetMapping("/noExecutor") public Object noExecutor() throws InterruptedException &#123; long a =System.currentTimeMillis(); sleep1(); sleep2(); long b = System.currentTimeMillis(); JSONObject object = new JSONObject(); object.put("同步耗时",b-a); return object; &#125; &#125; 1结果： &#123;"同步耗时":5001&#125; 使用 TaskExecutor 手动完成异步任务在springboot启动文件中，添加 @EnableAsync 注解 1234567@EnableAsync@SpringBootApplicationpublic class LearnningApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LearnningApplication.class, args); &#125;&#125; 新建一个线程池配置类 1234567891011121314151617181920212223@Configuration@EnableAsyncpublic class ThreadPoolConfig &#123; private ThreadPoolTaskExecutor getExecutor()&#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(100); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); return executor; &#125; // 这里新建了两个 ThreadPoolTaskExecutor ，根据业务需求更改 @Primary @Bean("taskExecutor") public ThreadPoolTaskExecutor taskExecutor()&#123; return getExecutor(); &#125; @Bean("otherExecutor") public ThreadPoolTaskExecutor otherExecutor()&#123; return getExecutor(); &#125;&#125; 在 controller 测试 123456789101112131415161718192021222324252627282930313233343536373839@RestController@RequestMapping("/user")public class UserController &#123; @Resource(name="taskExecutor") private ThreadPoolTaskExecutor taskExecutor; @Resource private UserManager userManager; @GetMapping("/taskExecutor") public Object taskExecutor() throws Exception &#123; long a =System.currentTimeMillis(); CountDownLatch countDownLatch = new CountDownLatch(2); taskExecutor.execute(()-&gt;&#123; try &#123; userManager.sleep1(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;); taskExecutor.execute(()-&gt;&#123; try &#123; userManager.sleep2(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;); countDownLatch.await(); long b = System.currentTimeMillis(); JSONObject object = new JSONObject(); object.put("异步耗时",b-a); return object; &#125;&#125; 1结果： &#123;"异步耗时":3002&#125; 使用 TaskExecutor 注解完成异步任务只需要将 service 层的方法加上 @Async(&quot;taskExecutor&quot;) 注解 12345678910111213@Servicepublic class UserManager &#123; // 模拟耗时业务 @Async("taskExecutor") public void sleep3() throws InterruptedException &#123; //必须无返回值，或者返回future Thread.sleep(3000); &#125; // 模拟耗时业务 @Async("taskExecutor") public void sleep4() throws InterruptedException &#123; Thread.sleep(3000); &#125;&#125; 1234567891011@GetMapping("/anoTaskExecutor")public Object anoTaskExecutor() throws Exception &#123; long a =System.currentTimeMillis(); userManager.sleep3(); userManager.sleep4(); long b = System.currentTimeMillis(); JSONObject object = new JSONObject(); object.put("异步耗时",b-a); return object;&#125; 1结果： &#123;"异步耗时":1&#125; 使用 FutureTask 完成异步任务12345678910111213141516171819202122232425262728@GetMapping("/futureTask")public Object futureTask() throws ExecutionException, InterruptedException &#123; long a =System.currentTimeMillis(); List&lt;FutureTask&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); FutureTask&lt;Integer&gt; futureTask1 = new FutureTask&lt;&gt;(()-&gt;&#123; return userManager.sleep1(); &#125;); list.add(futureTask1); FutureTask&lt;Integer&gt; futureTask2 = new FutureTask&lt;&gt;(()-&gt;&#123; return userManager.sleep2(); &#125;); list.add(futureTask2); list.parallelStream().forEach(futureTask-&gt;&#123; taskExecutor.submit(futureTask); &#125;); int i =0; for (FutureTask&lt;Integer&gt; futureTask:list) &#123; i+=futureTask.get(); //获取异步任务结果 &#125; long b = System.currentTimeMillis(); JSONObject object = new JSONObject(); object.put("耗时",b-a); object.put("结果",i); return object;&#125; 1结果： &#123;"耗时":3001,"结果":5&#125;]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>futuretask</tag>
        <tag>taskexecutor</tag>
        <tag>springboot</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat 解析]]></title>
    <url>%2F2019%2F07%2F07%2Fmycat-%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[主要作用 作为分布式数据库中间层 实现读写分离和负载均衡 对业务数据库进行垂直切分 对业务数据库进行水平切分 控制数据库连接的数量 基本元素逻辑库 对应用来说相当于mysql中的数据库 逻辑库可对应后端多个物理数据库 逻辑库中并不保存数据 逻辑表含义 对应用来说相当于mysql中的数据表 逻辑表可对应后端多个物理数据表 逻辑表中并不保存数据 类别 分片表与非分片表按是否被分片划分 全局表，在所有分片中都存在的表 ER 关系表，按ER关系进行分片的表 未完待续……]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[魔镜心灵]]></title>
    <url>%2F2019%2F06%2F29%2F%E9%AD%94%E9%95%9C%E5%BF%83%E7%81%B5%2F</url>
    <content type="text"><![CDATA[执意要看，请输入暗号 ！ Incorrect Password! No content to display! U2FsdGVkX1+U371hQQn0sbUhvNRHCyqhZawWXGA1xOPWoyTQ3A4b1uOAwYHP2BgKKVXlET26AsyzGExuCJYDecAWz5rdSuUKAqJJOg5Tnvdksck8XiODbMa8BCs3ZHWVD8BgtwZoMEHqBlSik3gdf/CTqazGARkQYtLcFApaEMi2J9kpfWGYDeWNIRRag2xWY+BAumtgpMM9hiszECaowKaA9XCi5Cq/QKADD6Zcw7K4r6Aaui8xSh1CCvB7W9iKmT5G7f6izP2DXGNDPMtDw6TFFtuY8hrQPREAL4qIVxLrqUswqjrj5tOqwpMfEnZmA3Q79cYCLcaDF91YuVNt7n6Zzgh/fLm3kPUDeWFBQWYHjmUjCEbSf+2TGvKVWiclUB2mg1bBJ+t6RGK4s0tZacXZOS8AhFl3nfABI7VsZXJelq1UwTQkaiiXfh++58wO02P3BaR07ocDqHmMu1QROHWizwbIgsX6Zlpxi8xaxYn/sJ/LkF1fXWuBWhijEqcpON6a+on6sUU+KnHV6NPqlkxanz/jKaxJnr+ts9fSduAFfxzpU7m6YztwJiBj0ldT0RaNgjOjUOLAaLTlKUgdDA0BbwL+ghtum7G+Fuv/DDaspz7/459NPzd4Fpmc57OT9ZDQHGFNSTyGLMunoc2BaLgTEOYvp5HEWV49Sq4ZJCbLonwOENR314K5uW9X+jvzcd5gaYdJaRlqww4gwJ/ycx/DQwddw1TltCpFR1IOih3HNFYz6nyBoySfIacK4p1H2sIEmKoctD83+Kaxwlo2rJakDpkoznJKG0iUiqEdUwSKYbE+xsIjc7stp0h6qCyARQi+fVEEPVTWfaGEZ8YluuPEPEKIrb8NUaLPLknj6dNIkj/bQ/HswCrD32ZnWp0f37WBvq5EG1lTU+CnsdBZgAyMQKTQjFBgRbCTr8siB7Pf1AKlc8DK/Om9i8y+kk1Q5MPPwMlvOjvTf5teuU5gD4u2ZEkggZYDohxb66irXUpGpnGnqA6vmPYHOA6brZCFMjxCG1eZuDhg++2tNUAWBRnc8Kbk9VvS9xkMLl80Fon5gmEOWh48Y78WKgDrgq8mKjDqNLGW+TseSLl/DzHUe6XruC+7oOCmxn4fJ++9J92qZ6OFhWRuweBN65IS3W8bMJUM/0O3ZGy3WD4iRSQ+deYvzwv3DeHIddyrrCE4lxCM1XqCYmLFGQe5MJKYgq48MRKtoOqJKzp9zVJgnyIk7GXWs+B5mcjfSfCI51ZXo+nAmLJedKwYHAeVFayEgeoJCfmCgKAPeJr5CblWctO2IwojemXJThZumxVLeCFy6yHJuk7Uv1dIJqGyo0AHpa9L4w6DsSFcwppbIMm3Q2chnDVPJQ60gO1UFhLqn3rao8fHmzrvn2421LQX2dYWRIU/DalX+eBlawcM6LqBHtuuUPsbha31Oqir8Reyl01gTKloH3CDz/HgGacQA0KquZIH43YLejGUmt6DprGt79W+YBlX0h2cUfDCJq7+shDYjwa5Io4eXElsmE3PF5Z1yXnlzqzCcY1IxKYIIAdBh05Md1Y0BqmqvG2ludCXpIoDPo8Rod8pkabFgRSuO2YQkG82vfDMhEEpbIaTJ19PaZ34PMdTzfUOUNmiAoFilwQTWlPK2KhMIMBzNMXUMUdxxzISfzXFnbEDGmPxFdLRJho8Sl4zy1tAXRkZCs1L3b/kbzG/qzyAxve43qWrPF7FYBIMzay3u8mc7ABAYGYPB/4QzAM+S9i45O5f51uRgAlhEiMF8rCxfMjY4Oh0k5/amZ8I0REFa8ecK5K1ZBmtxUOYJJQWLraol5uqUUUWrnAc2l3v/6L9hgVq6Z8krvV08uXROCxlzVdT1qCZytYYyZd60RgiSOP5sRrPEQLP2j2fcYUa0+bcnt95RTlBCBPbau3tCB1IkAgT04pvyogBVri5okbt2q/smbLxwnCQDR8UUkXC4VjCsVJxNPy+LVXOkPdE]]></content>
      <categories>
        <category>生活随笔</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 实用插件]]></title>
    <url>%2F2019%2F06%2F29%2FHexo-%E5%AE%9E%E7%94%A8%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[搜索插件进入博客根目录，从cmd输入以下命令 1npm install hexo-generator-searchdb --save 修改 站点配置 文件，注意 search.xml 的路径 12345search: path: search.xml field: post format: html limit: 10000 修改 主题配置 文件，搜索 local_search 12local_search: enable: true GIT 插件进入博客根目录，从cmd输入以下命令 1npm install hexo-deployer-git --save 修改 站点配置 文件 1234deploy: type: git repo: https://github.com/eaphy/eaphy.github.io.git branch: master 加密插件进入博客根目录，从cmd输入以下命令 1npm install --save hexo-blog-encrypt 修改 站点配置 文件 123# Securityencrypt: enable: true 在文章头部加入： 123456789---title: 测试密码tags:categories:date: 2019-06-29 16:54:51password: 123456abstract: 加密文章，点击 阅读全文，输入密码之后访问全文 ！message: 请输入密码，回车查看文章内容 ！--- 图片懒加载插件进入博客根目录，从cmd输入以下命令 1npm install hexo-lazyload-image --save 修改 站点配置 文件，添加以下内容 1234lazyload: enable: true onlypost: false loadingImg: /images/loading.png 文章置顶插件进入博客根目录，从cmd输入以下命令 12$ npm uninstall hexo-generator-index --save$ npm install hexo-generator-index-pin-top --save 修改 /themes/next/layout/_macro/post.swig文件，搜索 &lt;div class=&quot;post-meta&quot;&gt; ，在其下一行添加以下内容： 12345&#123;% if post.top %&#125; &lt;i class="fa fa-thumb-tack"&gt;&lt;/i&gt; &lt;font color=696969&gt;置顶&lt;/font&gt; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt;&#123;% endif %&#125; 在文章头部加入：top: true 1234567---title: 测试置顶tags:categories:top: truedate: 2019-06-29 16:54:51---]]></content>
      <categories>
        <category>网站运维</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常见命令]]></title>
    <url>%2F2019%2F06%2F28%2FLinux-%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[uptime精简版显示系统负载均衡。load average: 0.00, 0.09, 0.10， 分别代表1分钟、5分钟、15分钟的负载均衡。 12[root@localhost ~]# uptime 13:54:10 up 9 min, 2 users, load average: 0.00, 0.09, 0.10 top查看整机系统性能。 12345678910111213141516171819202122232425[root@localhost ~]# toptop - 13:54:04 up 9 min, 2 users, load average: 0.00, 0.09, 0.10Tasks: 448 total, 2 running, 446 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3866948 total, 2971808 free, 483016 used, 412124 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 3144672 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2500 mysql 20 0 1182556 188432 10056 S 0.6 4.9 0:01.52 mysqld 1 root 20 0 189244 4232 2408 S 0.0 0.1 0:02.52 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.01 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 6 root 20 0 0 0 0 S 0.0 0.0 0:00.05 kworker/u256:0 7 root rt 0 0 0 0 S 0.0 0.0 0:00.07 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/0 10 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/1 11 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/2 12 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/3 13 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/4 14 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/5 15 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/6 16 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/7 17 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/8 输入top 回车后，按数字 1 键可以显示多核cpu各核的使用情况。按字母 q 键退出 top 1234567891011121314151617181920212223242526272829303132top - 13:57:30 up 12 min, 2 users, load average: 0.00, 0.04, 0.08Tasks: 448 total, 2 running, 446 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu6 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu7 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3866948 total, 2972008 free, 482760 used, 412180 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 3144884 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2500 mysql 20 0 1182556 188432 10056 S 0.6 4.9 0:01.52 mysqld 1 root 20 0 189244 4232 2408 S 0.0 0.1 0:02.52 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.01 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 6 root 20 0 0 0 0 S 0.0 0.0 0:00.05 kworker/u256:0 7 root rt 0 0 0 0 S 0.0 0.0 0:00.07 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/0 10 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/1 11 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/2 12 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/3 13 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/4 14 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/5 15 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/6 16 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/7 17 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcuob/8 free查看系统内存。 -m 以兆为单位显示，-g 以G为单位显示 123456789101112[root@localhost ~]# free total used free shared buff/cache availableMem: 3866948 482152 2972304 9328 412492 3145432Swap: 2097148 0 2097148[root@localhost ~]# free -m total used free shared buff/cache availableMem: 3776 471 2902 9 402 3071Swap: 2047 0 2047[root@localhost ~]# free -g total used free shared buff/cache availableMem: 3 0 2 0 0 2Swap: 1 0 df文件系统的磁盘空间占用情况 。 -h 表示以常用单位显示 。 1234567891011121314151617181920[root@localhost ~]# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/mapper/centos-root 18307072 9416900 8890172 52% /devtmpfs 1918188 0 1918188 0% /devtmpfs 1933472 84 1933388 1% /dev/shmtmpfs 1933472 9224 1924248 1% /runtmpfs 1933472 0 1933472 0% /sys/fs/cgroup/dev/sda1 508588 160364 348224 32% /boottmpfs 386696 0 386696 0% /run/user/0tmpfs 386696 16 386680 1% /run/user/42[root@localhost ~]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/centos-root 18G 9.0G 8.5G 52% /devtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 84K 1.9G 1% /dev/shmtmpfs 1.9G 9.1M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda1 497M 157M 341M 32% /boottmpfs 378M 0 378M 0% /run/user/0tmpfs 378M 16K 378M 1% /run/user/42 vmstat显示虚拟内存状态（“Viryual Memor Statics”），它可以显示进程、内存、I/O等系统整体运行状态。 1234567891011[root@localhost ~]# vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 2972176 1260 411324 0 0 25 2 23 30 0 0 99 1 0 [root@localhost ~]# vmstat -n 2 3 // 2 秒刷新一次，共 3 次procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 2972036 1260 411324 0 0 25 2 23 30 0 0 99 1 0 0 0 0 2972160 1260 411324 0 0 0 0 71 125 0 0 100 0 0 0 0 0 2972160 1260 411324 0 0 0 0 64 109 0 0 100 0 0 字段解释： r: 运行队列中进程数量，这个值也可以判断是否需要增加CPU。（长期大于1） b: 等待IO的进程数量。 swpd:使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。 free: 空闲物理内存大小。 id: 空闲时间百分比 mpstat查看所有 cpu 核信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost ~]# mpstat // 输出为从系统启动以来的平均值。Linux 3.10.0-327.el7.x86_64 (localhost.localdomain) 2019年06月29日 _x86_64_ (8 CPU)14时23分28秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle14时23分28秒 all 0.02 0.00 0.14 0.38 0.00 0.00 0.00 0.00 0.00 99.45[root@localhost ~]# mpstat -P ALL 2 3 // 查看所有cpu核信息，2 秒刷新一次，共 3 次Linux 3.10.0-327.el7.x86_64 (localhost.localdomain) 2019年06月29日 _x86_64_ (8 CPU)14时31分16秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle14时31分18秒 all 0.00 0.00 0.06 0.00 0.00 0.00 0.00 0.00 0.00 99.9414时31分18秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 3 0.00 0.00 0.50 0.00 0.00 0.00 0.00 0.00 0.00 99.5014时31分18秒 4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分18秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle14时31分20秒 all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分20秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle14时31分22秒 all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 1 0.00 0.00 0.49 0.00 0.00 0.00 0.00 0.00 0.00 99.5114时31分22秒 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0014时31分22秒 7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle平均时间: all 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00 0.00 99.98平均时间: 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: 1 0.00 0.00 0.17 0.00 0.00 0.00 0.00 0.00 0.00 99.83平均时间: 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: 3 0.00 0.00 0.17 0.00 0.00 0.00 0.00 0.00 0.00 99.83平均时间: 4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: 6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: 7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 pidstat用于监控全部或指定进程占用系统资源的情况，如CPU，内存、设备IO、任务切换、线程等。 12345678910111213141516171819202122232425[root@localhost ~]# pidstat //查看全部进程cpu使用信息Linux 3.10.0-327.el7.x86_64 (localhost.localdomain) 2019年06月29日 _x86_64_ (8 CPU)14时33分54秒 UID PID %usr %system %guest %CPU CPU Command14时33分54秒 0 1 0.00 0.11 0.00 0.11 0 systemd14时33分54秒 0 2 0.00 0.00 0.00 0.00 6 kthreadd14时33分54秒 0 3 0.00 0.00 0.00 0.00 0 ksoftirqd/014时33分54秒 0 6 0.00 0.00 0.00 0.00 3 kworker/u256:014时33分54秒 0 7 0.00 0.00 0.00 0.00 0 migration/014时33分54秒 0 137 0.00 0.04 0.00 0.04 3 rcu_sched14时33分54秒 0 138 0.00 0.01 0.00 0.01 2 rcuos/0[root@localhost ~]# pidstat -U 1 5 -p 2977 //查看 2977 进程cpu使用信息，1 秒一次，采集 5 次Linux 3.10.0-327.el7.x86_64 (localhost.localdomain) 2019年06月29日 _x86_64_ (8 CPU)14时36分50秒 USER PID %usr %system %guest %CPU CPU Command14时36分51秒 gdm 2977 0.00 0.00 0.00 0.00 7 goa-identity-se14时36分52秒 gdm 2977 0.00 0.00 0.00 0.00 7 goa-identity-se14时36分53秒 gdm 2977 0.00 0.00 0.00 0.00 7 goa-identity-se14时36分54秒 gdm 2977 0.00 0.00 0.00 0.00 7 goa-identity-se14时36分55秒 gdm 2977 0.00 0.00 0.00 0.00 7 goa-identity-se平均时间: gdm 2977 0.00 0.00 0.00 0.00 - goa-identity-se[root@localhost ~]# pidstat -r 1 5 -p 2977 //查看 2977 进程内存的统计信息，1 秒一次，采集 5 次[root@localhost ~]# pidstat -d 1 5 -p 2977 //查看 2977 进程 IO的统计信息，1 秒一次，采集 5 次 iostat查看磁盘IO信息。 1234567891011[root@localhost ~]# iostatLinux 3.10.0-327.el7.x86_64 (localhost.localdomain) 2019年06月29日 _x86_64_ (8 CPU)avg-cpu: %user %nice %system %iowait %steal %idle 0.02 0.00 0.11 0.26 0.00 99.61Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 4.32 106.80 10.54 366872 36194scd0 0.00 0.01 0.00 44 0dm-0 3.67 97.95 9.93 336460 34125dm-1 0.04 0.37 0.00 1268 0 ifstat查看网络IO信息。 12345678910[root@localhost ~]# ifstat#kernelInterface RX Pkts/Rate TX Pkts/Rate RX Data/Rate TX Data/Rate RX Errs/Drop TX Errs/Drop RX Over/Rate TX Coll/Rate lo 4 0 4 0 340 0 340 0 0 0 0 0 0 0 0 0 eno16777736 1478 0 1307 0 118781 0 945129 0 0 0 0 0 0 0 0 0 virbr0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 awk]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池解析]]></title>
    <url>%2F2019%2F06%2F28%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[线程池作用 利用线程池管理并复用线程、控制最大并发数等 实现任务线程队列缓存策略和拒绝机制 实现某些与时间相关的功能，如定时执行、周期执行等 隔离线程环境，比如，交易服务和搜索服务在同一台服务器上,分别开启两个线程池,交易线程的资源消耗明显要大;因此,通过配置独立的线程池,将较慢的交易服务与搜索服务隔离开,避免各服务线程相互影响. 线程池好处 降低资源消耗： 通过重复利用已创建的线程,降低创建和销毁线程造成的系统资源消耗 提高响应速度： 当任务到达时,任务可以不需要等到线程创建就能立即执行 提高线程的可管理性： 线程是稀缺资源,如果过多地创建,不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 线程池构造解析123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 七个参数解析： 1. corePoolSize线程池中的常驻核心线程数，一般不会被回收。如果 executor.allowCoreThreadTimeOut(true) ，那么核心线程如果不干活(闲置状态)的话，超过一定时间( keepAliveTime)，就会被销毁掉 2. maximumPoolSize线程池能容纳同时执行的最大线程数，线程总数计算公式 = 核心线程数 + 非核心线程数。 3. keepAliveTime 非核心空闲线程的存活时间。 4. TimeUnit keepAliveTime 的时间单位。 5. workQueue 任务队列，存放被提交但尚未执行的任务。 6. threadFactory生成线程池中工作线程的线程工厂。 7. handler 拒绝策略。 hreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列等待最久的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 JDK 自带的线程池123456// 单线程Executor executor1 = Executors.newSingleThreadExecutor();// 固定长度Executor executor2 = Executors.newFixedThreadPool(5);// 可扩展，随需创建线程数Executor executor3 = Executors.newCachedThreadPool(); 一般不会直接使用以上三种，而是手写 ThreadPoolExecutor 实现线程池，因为阻塞队列的最大值为 Integer.MAX_VALUE ，会造成OOM。 合理配置线程池1. cpu 密集型：(需要大量运算，不会阻塞，宜少配置线程数) cpu核心数+1 2. IO 密集型：（需要大量IO，会阻塞，宜多配置线程数） cpu核心数*2]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 原理解析]]></title>
    <url>%2F2019%2F06%2F28%2Fzookeeper-%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[zookeeper 简介 ZooKeeper 是一个开源的分布式协调服务，是 Apache 顶级项目 Hadoop 中非常重要的组件。 zookeeper 作用 统一配置、分布式锁、集群管理、注册中心、分布式队列 zookeeper 结构 数据模型 ZooKeeper 数据模型的结构与Unix文件系统很类似，每个节点称作一个ZNode，ZNode 是以 key-value 形式存在的。 重要概念 Znode：zookeeper 中每个文件系统路径就是一个节点。节点有四种： PERSISTENT-持久化节点客户端与zookeeper断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL-持久化顺序节点客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL-临时节点客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL-临时顺序节点客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 会话：(Session)Session 指的是 ZooKeeper 服务器与客户端会话，是一个 TCP 长连接。通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，同时还能够接收来自服务器的 Watch 事件通知。在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionID，且具有全局唯一性。 版本：zookeeper 为数据节点引入了版本的概念。存在于一个Stat 的数据结构中，记录了这个 ZNode 的三个数据版本，分别是：dataversion（当前 ZNode 的版本）、cversion（当前 ZNode 子节点的版本）、aclversion（当前 ZNode 的 ACL 版本）。用于保证分布式数据原子性操作。 watcher：Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。事件监听是一次性的，如果希望收到有关未来更改的通知，则必须设置另一个监听。 ACL：zookeeper 通过acl机制来实现对数据节点的权限控制。主要有五种权限： create 创建权限 delete 子节点的删除权限 read 读取权限 write 更新权限 admin 管理权限，能够进行ACL设置 zookeeper 特点 顺序一致性：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。 zookeeper 角色 Leader 提供读写 Follower 提供读 Observer 提供读，不参与选举 zookeeper 原理Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步，实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上 了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个 新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。 每个Server在工作过程中有三种状态： （1）LOOKING：当前Server不知道leader是谁，正在搜寻。（2）LEADING：当前Server即为选举出来的leader。（3）FOLLOWING：leader已经选举出来，当前Server与之同步。 选主流程当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的 Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，一种是基于fast paxos实现的。系统默认为fast paxos。（1）Basic paxos：当前Server发起选举的线程,向所有Server发起询问,选举线程收到所有回复,计算zxid最大Server,并推荐此为leader，若此提议获得n/2+1票通过,此为leader，否则重复上述流程，直到leader选出。（2）Fast paxos：某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。(即提议方解决其他所有epoch和 zxid的冲突,即为leader)。 同步流程（1）Leader等待server连接；（2）Follower连接leader，将最大的zxid发送给leader；（3）Leader根据follower的zxid确定同步点，完成同步后通知follower 已经成为uptodate状态；（4）Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。]]></content>
      <categories>
        <category>开源框架</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github+Next 搭建个人博客]]></title>
    <url>%2F2019%2F06%2F26%2FHexo-Github-Next-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[1. 在 github 建立 repository2. 安装 node.js 和 git3. 安装 hexo 从G盘输入cmd，回车，输入以下命令 1234npm install hexo-cli -ghexo init Eaphy's-Blog //文件夹名字cd Eaphy's-Blognpm install 4. 安装 Next 12cd Eaphy&apos;s-Bloggit clone https://github.com/iissnan/hexo-theme-next themes/next 5. 配置博客 编辑站点中 _config.yml ,启用 next 主题，切换中文语言 1theme: next 1language: zh-CN 编辑主题中 _config.yml ,选择 Pisces Scheme 123#scheme: Muse#scheme: Mistscheme: Pisces 6.拉取仓库代码到本地 1234567891011121314151617# 拉取代码cd Eaphy's-Bloggit clone https://github.com/eaphy/eaphy.github.io.git ./publichexo g# 提交代码cd public git add .git commit -m "first commit"git push]]></content>
      <categories>
        <category>网站运维</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>next</tag>
      </tags>
  </entry>
</search>
